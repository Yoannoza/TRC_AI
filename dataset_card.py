import os
import json
from pathlib import Path
from huggingface_hub import HfApi, login
import pandas as pd
from typing import Dict, List, Set, Tuple
import logging
from datetime import datetime
from collections import Counter, defaultdict
from dotenv import load_dotenv

load_dotenv()

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class GenerateurCarteDatasetComplet:
    """G√©n√©rer une carte de dataset compl√®te pour Hugging Face Hub"""
    
    def __init__(self, dataset_path: str, repo_name: str):
        self.dataset_path = Path(dataset_path)
        self.repo_name = repo_name
        self.api = HfApi()
        
        # V√©rifier que le dataset existe
        if not self.dataset_path.exists():
            raise FileNotFoundError(f"Chemin du dataset introuvable : {dataset_path}")
    
    def login_hf(self, token: str = None):
        """Connexion √† Hugging Face"""
        if token:
            login(token=token)
        else:
            login()
        logger.info("Connect√© √† Hugging Face")
    
    def analyser_dataset(self) -> Dict:
        """Analyser le dataset et extraire des statistiques compl√®tes"""
        logger.info("Analyse du dataset en cours...")
        
        metadata_files = list((self.dataset_path / "metadata").glob("*.json"))
        
        if not metadata_files:
            raise ValueError("Aucun fichier de m√©tadonn√©es trouv√©")
        
        # Initialiser les conteneurs d'analyse
        analysis = {
            'total_images': len(metadata_files),
            'waste_types': Counter(),
            'zones': Counter(),
            'categories': Counter(),
            'colors': Counter(),
            'materials': Counter(),
            'shapes': Counter(),
            'sizes': Counter(),
            'degradation_states': Counter(),
            'environments': Counter(),
            'lighting_conditions': Counter(),
            'backgrounds': Counter(),
            'zone_waste_distribution': defaultdict(Counter),
            'category_zone_distribution': defaultdict(Counter),
            'file_sizes': [],
            'missing_images': [],
            'generation_date_range': {'earliest': None, 'latest': None}
        }
        
        # Analyser chaque fichier de m√©tadonn√©es
        for metadata_file in metadata_files:
            try:
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                
                # V√©rifier si l'image existe
                image_path = Path(metadata.get('image_path', ''))
                if not image_path.exists():
                    analysis['missing_images'].append(str(metadata_file))
                    continue
                
                # Obtenir la taille du fichier
                try:
                    size_mb = image_path.stat().st_size / (1024 * 1024)
                    analysis['file_sizes'].append(size_mb)
                except:
                    pass
                
                # Extraire les champs de m√©tadonn√©es
                waste_type = metadata.get('waste_type', 'inconnu')
                zone = metadata.get('zone', 'inconnue')
                category = metadata.get('category', 'inconnue')
                variations = metadata.get('variations', {})
                
                # Compter les occurrences
                analysis['waste_types'][waste_type] += 1
                analysis['zones'][zone] += 1
                analysis['categories'][category] += 1
                analysis['zone_waste_distribution'][zone][waste_type] += 1
                analysis['category_zone_distribution'][category][zone] += 1
                
                # Compter les variations
                for key in ['color', 'material', 'shape', 'size', 'degradation', 
                           'environment', 'lighting', 'background']:
                    value = variations.get(key, 'inconnu')
                    if key == 'degradation':
                        analysis['degradation_states'][value] += 1
                    elif key == 'lighting':
                        analysis['lighting_conditions'][value] += 1
                    else:
                        analysis[f"{key}s"][value] += 1
                
                # Suivre les dates de g√©n√©ration
                gen_date = metadata.get('generated_at')
                if gen_date:
                    if not analysis['generation_date_range']['earliest'] or gen_date < analysis['generation_date_range']['earliest']:
                        analysis['generation_date_range']['earliest'] = gen_date
                    if not analysis['generation_date_range']['latest'] or gen_date > analysis['generation_date_range']['latest']:
                        analysis['generation_date_range']['latest'] = gen_date
                        
            except Exception as e:
                logger.warning(f"Erreur lors du traitement de {metadata_file}: {e}")
                continue
        
        # Calculer des statistiques suppl√©mentaires
        if analysis['file_sizes']:
            analysis['avg_file_size_mb'] = sum(analysis['file_sizes']) / len(analysis['file_sizes'])
            analysis['total_size_mb'] = sum(analysis['file_sizes'])
        else:
            analysis['avg_file_size_mb'] = 0
            analysis['total_size_mb'] = 0
        
        logger.info(f"Analyse termin√©e : {analysis['total_images']} images analys√©es")
        return analysis
    
    def creer_entete_yaml(self, analysis: Dict) -> str:
        """Cr√©er l'en-t√™te YAML pour la carte du dataset"""
        
        # Extraire les valeurs uniques pour les tags
        waste_types = list(analysis['waste_types'].keys())
        categories = list(analysis['categories'].keys())
        zones = list(analysis['zones'].keys())
        
        yaml_header = f"""---
            license: cc-by-4.0
            task_categories:
            - image-classification
            - object-detection
            - computer-vision
            language:
            - fr
            - en
            tags:
            - donnees-synthetiques
            - gestion-dechets
            - ia-environnementale
            - vision-par-ordinateur
            - classification-images
            - detection-objets
            - recyclage
            - durabilite
            - detection-dechets
            - contexte-africain
            size_categories:
            - {self._obtenir_categorie_taille(analysis['total_images'])}
            dataset_info:
            features:
            - name: image
                dtype: image
            - name: waste_type
                dtype: string
            - name: zone
                dtype: string
            - name: category
                dtype: string
            - name: color
                dtype: string
            - name: material
                dtype: string
            - name: shape
                dtype: string
            - name: size
                dtype: string
            - name: degradation
                dtype: string
            - name: environment
                dtype: string
            - name: lighting
                dtype: string
            - name: background
                dtype: string
            - name: prompt
                dtype: string
            splits:
            - name: train
                num_bytes: {int(analysis['total_size_mb'] * 0.8 * 1024 * 1024)}
                num_examples: {int(analysis['total_images'] * 0.8)}
            - name: test
                num_bytes: {int(analysis['total_size_mb'] * 0.2 * 1024 * 1024)}
                num_examples: {int(analysis['total_images'] * 0.2)}
            download_size: {int(analysis['total_size_mb'] * 1024 * 1024)}
            dataset_size: {int(analysis['total_size_mb'] * 1024 * 1024)}
            configs:
            - config_name: default
            data_files:
            - split: train
                path: data/train-*
            - split: test
                path: data/test-*
        ---"""
        return yaml_header
            
    def _obtenir_categorie_taille(self, num_images: int) -> str:
        """Obtenir la cat√©gorie de taille pour le dataset"""
        if num_images < 1000:
            return "n<1K"
        elif num_images < 10000:
            return "1K<n<10K"
        elif num_images < 100000:
            return "10K<n<100K"
        elif num_images < 1000000:
            return "100K<n<1M"
        else:
            return "n>1M"
    
    def creer_carte_complete(self, analysis: Dict) -> str:
        """Cr√©er une carte de dataset compl√®te"""
        
        # En-t√™te YAML
        yaml_header = self.creer_entete_yaml(analysis)
        
        # Contenu principal
        card_content = f"""
        # üóëÔ∏è Dataset Synth√©tique de D√©chets pour la Gestion Environnementale Pilot√©e par l'IA

        ## üìä Aper√ßu du Dataset

        Ce dataset contient **{analysis['total_images']:,} images synth√©tiques de haute qualit√©** de diff√©rents types de d√©chets, con√ßues pour entra√Æner des mod√®les de vision par ordinateur destin√©s √† la d√©tection, classification et gestion des d√©chets. Les images sont g√©n√©r√©es √† l'aide de techniques d'IA de pointe et couvrent divers environnements urbains africains, incluant les zones r√©sidentielles, commerciales et industrielles.

        ### üéØ Caract√©ristiques Cl√©s

        - **{analysis['total_images']:,} images synth√©tiques** r√©parties sur {len(analysis['waste_types'])} types de d√©chets
        - **{len(analysis['zones'])} zones distinctes** : {', '.join(analysis['zones'].keys())}
        - **{len(analysis['categories'])} cat√©gories de d√©chets** : {', '.join(analysis['categories'].keys())}
        - **M√©tadonn√©es riches** avec plus de 12 attributs par image
        - **Focus sur le contexte africain** avec des environnements localis√©s
        - **Images haute r√©solution** ({analysis['avg_file_size_mb']:.2f} MB en moyenne)
        - **Variations compl√®tes** en √©clairage, mat√©riaux, √©tats de d√©gradation

        ## üèóÔ∏è Structure du Dataset

        ### R√©partition des Images par Zone
        {self._creer_tableau_distribution(analysis['zones'], 'Zone', 'Images')}

        ### R√©partition des Types de D√©chets
        {self._creer_tableau_distribution(analysis['waste_types'], 'Type de D√©chet', 'Images')}

        ### R√©partition des Cat√©gories
        {self._creer_tableau_distribution(analysis['categories'], 'Cat√©gorie', 'Images')}

        ## üîç Statistiques D√©taill√©es

        ### Caract√©ristiques Physiques
        - **Couleurs** : {len(analysis['colors'])} variantes ({', '.join(list(analysis['colors'].keys())[:10])}{'...' if len(analysis['colors']) > 10 else ''})
        - **Mat√©riaux** : {len(analysis['materials'])} types ({', '.join(list(analysis['materials'].keys()))})
        - **Formes** : {len(analysis['shapes'])} formes ({', '.join(list(analysis['shapes'].keys()))})
        - **Tailles** : {len(analysis['sizes'])} cat√©gories ({', '.join(list(analysis['sizes'].keys()))})
        - **√âtats de D√©gradation** : {len(analysis['degradation_states'])} niveaux ({', '.join(list(analysis['degradation_states'].keys()))})

        ### Contexte Environnemental
        - **Environnements** : {len(analysis['environments'])} lieux ({', '.join(list(analysis['environments'].keys())[:5])}{'...' if len(analysis['environments']) > 5 else ''})
        - **Conditions d'√âclairage** : {len(analysis['lighting_conditions'])} types ({', '.join(list(analysis['lighting_conditions'].keys()))})
        - **Arri√®re-plans** : {len(analysis['backgrounds'])} variantes ({', '.join(list(analysis['backgrounds'].keys())[:5])}{'...' if len(analysis['backgrounds']) > 5 else ''})

        ### Sp√©cifications Techniques
        - **Taille Totale du Dataset** : {analysis['total_size_mb']:.1f} MB
        - **Taille Moyenne d'Image** : {analysis['avg_file_size_mb']:.2f} MB
        - **Format d'Image** : PNG
        - **R√©solution** : 1024x1024 pixels
        - **P√©riode de G√©n√©ration** : {analysis['generation_date_range']['earliest'][:10] if analysis['generation_date_range']['earliest'] else 'N/A'} √† {analysis['generation_date_range']['latest'][:10] if analysis['generation_date_range']['latest'] else 'N/A'}

        ## üöÄ D√©marrage Rapide

        ### Chargement du Dataset

        ```python
        from datasets import load_dataset

        # Charger le dataset complet
        dataset = load_dataset("{self.repo_name}")

        # Charger une division sp√©cifique
        train_dataset = load_dataset("{self.repo_name}", split="train")
        test_dataset = load_dataset("{self.repo_name}", split="test")

        # Afficher les informations de base
        print(f"√âchantillons d'entra√Ænement : {{len(train_dataset)}}")
        print(f"√âchantillons de test : {{len(test_dataset)}}")
        print(f"Caract√©ristiques : {{train_dataset.features}}")
        ```

        ### Explorer les Donn√©es

        ```python
        import matplotlib.pyplot as plt
        from collections import Counter

        # Charger le dataset
        dataset = load_dataset("{self.repo_name}", split="train")

        # Afficher une image avec ses m√©tadonn√©es
        sample = dataset[0]
        plt.figure(figsize=(10, 6))

        plt.subplot(1, 2, 1)
        plt.imshow(sample['image'])
        plt.title(f"{{sample['waste_type']}} dans {{sample['zone']}}")
        plt.axis('off')

        plt.subplot(1, 2, 2)
        metadata_text = f"""
        Type_de_D√©chet : {{sample['waste_type']}}
        Zone : {{sample['zone']}}
        Cat√©gorie : {{sample['category']}}
        Couleur : {{sample['color']}}
        Mat√©riau : {{sample['material']}}
        Taille : {{sample['size']}}
        Environnement : {{sample['environment']}}
        √âclairage : {{sample['lighting']}}
        """
        plt.text(0.1, 0.5, metadata_text, fontsize=10, verticalalignment='center')
        plt.axis('off')
        plt.tight_layout()
        plt.show()

        # Analyser la distribution
        waste_types = [item['waste_type'] for item in dataset]
        waste_counter = Counter(waste_types)
        print("Top 5 des types de d√©chets :")
        for waste_type, count in waste_counter.most_common(5):
            print(f"  {{waste_type}} : {{count}} images")
        ```

        ## üéØ Cas d'Usage

        ### 1. **Mod√®les de Classification de D√©chets**
        Entra√Æner des mod√®les de classification d'images pour identifier diff√©rents types de d√©chets :
        ```python
        from transformers import AutoImageProcessor, AutoModelForImageClassification

        # Exemple avec un vision transformer
        processor = AutoImageProcessor.from_pretrained("google/vit-base-patch16-224")
        model = AutoModelForImageClassification.from_pretrained("google/vit-base-patch16-224", 
                                                            num_labels=len(unique_waste_types))
        ```

        ### 2. **Syst√®mes de D√©tection d'Objets**
        D√©velopper des syst√®mes de d√©tection de d√©chets pour les applications de ville intelligente :
        ```python
        # Convertir au format de d√©tection d'objets (YOLO, COCO)
        # Les annotations de bo√Ætes englobantes peuvent √™tre d√©riv√©es des objets de d√©chets centr√©s
        ```

        ### 3. **Surveillance Environnementale**
        Construire des syst√®mes automatis√©s pour :
        - üèôÔ∏è **Gestion de Ville Intelligente** : D√©tection automatis√©e de d√©chets en zones urbaines
        - ‚ôªÔ∏è **Optimisation du Recyclage** : Syst√®mes de tri automatis√©
        - üìä **Analytiques des D√©chets** : Surveillance des mod√®les et tendances de d√©chets
        - üåç **Recherche Environnementale** : √âtude de la distribution des d√©chets dans diff√©rentes zones

        ### 4. **Applications √âducatives**
        Parfait pour :
        - üéì **Cours de Vision par Ordinateur** : Enseigner la classification d'images et la d√©tection d'objets
        - üå± **√âducation Environnementale** : Sensibilisation √† la gestion des d√©chets
        - üî¨ **Projets de Recherche** : Base de r√©f√©rence pour la recherche en IA de gestion des d√©chets

        ## üìã Sch√©ma du Dataset

        | Caract√©ristique | Type | Description | Exemples de Valeurs |
        |------------------|------|-------------|---------------------|
        | `image` | Image | Image de d√©chet haute r√©solution | Objet PIL Image |
        | `waste_type` | string | Type sp√©cifique de d√©chet | "bouteille_plastique", "carton_emballage" |
        | `zone` | string | Zone environnementale | "r√©sidentielle", "commerciale", "industrielle" |
        | `category` | string | Cat√©gorie de d√©chet | "m√©nager", "recyclable", "dangereux" |
        | `color` | string | Couleur principale du d√©chet | "transparent", "bleu", "brun" |
        | `material` | string | Composition mat√©rielle | "PET", "carton ondul√©", "aluminium" |
        | `shape` | string | Forme physique | "cylindrique", "bo√Æte", "plat" |
        | `size` | string | Taille relative | "petit", "moyen", "grand" |
        | `degradation` | string | √âtat de condition | "neuf", "usag√©", "cass√©" |
        | `environment` | string | Lieu sp√©cifique | "Yamcity", "WalMart", "GDIZ" |
        | `lighting` | string | Condition d'√©clairage | "naturelle", "√©clairage LED", "projecteurs" |
        | `background` | string | Cadre d'arri√®re-plan | "rue pav√©e", "parking", "entrep√¥t" |
        | `prompt` | string | Prompt de g√©n√©ration | Description textuelle d√©taill√©e |

        ## üåç Contexte G√©ographique et Culturel

        Ce dataset se concentre sp√©cifiquement sur les **environnements urbains africains**, incluant :

        ### Zones R√©sidentielles
        - **Villes d'Afrique de l'Ouest** : Yamcity, Cotonou, Lagos, Accra, Bamako, Lom√©
        - **Cadres Typiques** : Quartiers locaux, march√©s traditionnels, rues r√©sidentielles

        ### Zones Commerciales  
        - **Centres Commerciaux** : WalMart, Super U, China Mall
        - **Districts d'Affaires** : Zones commerciales modernes √† travers l'Afrique de l'Ouest

        ### Zones Industrielles
        - **Zones √âconomiques** : GDIZ, Lagos Industrial Park, Ouagadougou Tech Zone
        - **Centres de Fabrication** : Bobo-Dioulasso Industrial Estate, Port Harcourt Energy Zone

        ## ‚öñÔ∏è Consid√©rations √âthiques et Limitations

        ### ‚úÖ Forces
        - **Donn√©es Synth√©tiques** : Aucun probl√®me de confidentialit√© avec de vraies personnes ou lieux
        - **Repr√©sentation Diverse** : Multiples contextes urbains africains
        - **Couverture Compl√®te** : Grande vari√©t√© de types et conditions de d√©chets
        - **Haute Qualit√©** : Images coh√©rentes et haute r√©solution

        ### ‚ö†Ô∏è Limitations
        - **Nature Synth√©tique** : Peut ne pas capturer toutes les nuances des d√©chets r√©els
        - **Port√©e G√©ographique** : Concentr√© sur les contextes africains (peut ne pas se g√©n√©raliser globalement)
        - **Instantan√© Temporel** : G√©n√©r√© √† une p√©riode sp√©cifique
        - **Artefacts IA** : Artefacts potentiels du processus de g√©n√©ration d'images

        ### ü§ù Usage Responsable
        - Compl√©ter avec des donn√©es r√©elles quand possible
        - Consid√©rer l'adaptation de domaine pour d'autres r√©gions g√©ographiques
        - Valider les performances du mod√®le sur des ensembles de test r√©els
        - Utiliser √† des fins √©ducatives et de recherche

        ## üìà R√©sultats de R√©f√©rence

        *√Ä venir : Performance des mod√®les de base sur diverses t√¢ches de vision par ordinateur*

        ## üîó Ressources Connexes

        - **[Rapport sur la Gestion des D√©chets en Afrique](https://example.com)** - Contexte sur les d√©fis des d√©chets
        - **[Vision par Ordinateur pour la Durabilit√©](https://example.com)** - Recherche connexe
        - **[Initiative Villes Intelligentes Africaines](https://example.com)** - Contexte d'impl√©mentation

        ## üìÑ Citation

        Si vous utilisez ce dataset dans votre recherche, veuillez citer :

        ```bibtex
        @dataset{{waste_synthetic_dataset_2024,
        title={{Dataset Synth√©tique de D√©chets pour la Gestion Environnementale Pilot√©e par l'IA}},
        author={{Votre Nom}},
        year={{2024}},
        publisher={{Hugging Face}},
        url={{https://huggingface.co/datasets/{self.repo_name}}}
        }}
        ```

        ## ü§ù Contribuer

        Nous accueillons les contributions pour am√©liorer ce dataset :

        1. **Signaler des Probl√®mes** : Trouv√© des donn√©es manquantes ou incorrectes ? Ouvrez un probl√®me
        2. **Sugg√©rer des Am√©liorations** : Id√©es pour des types de d√©chets ou environnements suppl√©mentaires
        3. **Partager les R√©sultats** : Faites-nous savoir comment vous utilisez le dataset
        4. **Collaborer** : Int√©ress√© par l'expansion du dataset ? Collaborons !

        ## üìû Contact

        Pour questions, suggestions ou collaborations, veuillez nous contacter via :
        - **Hugging Face** : [@{self.repo_name.split('/')[0]}](https://huggingface.co/{self.repo_name.split('/')[0]})
        - **D√©p√¥t du Dataset** : [Probl√®mes](https://huggingface.co/datasets/{self.repo_name}/discussions)

        ## üìú Licence

        Ce dataset est publi√© sous la **Licence Creative Commons Attribution 4.0 International (CC BY 4.0)**.

        Vous √™tes libre de :
        - ‚úÖ **Partager** : Copier et redistribuer le mat√©riel
        - ‚úÖ **Adapter** : Remixer, transformer et construire sur le mat√©riel
        - ‚úÖ **Usage Commercial** : Utiliser √† des fins commerciales

        Sous les conditions suivantes :
        - üìù **Attribution** : Donner un cr√©dit appropri√© et indiquer si des changements ont √©t√© apport√©s
        - üîó **Lien vers la Licence** : Inclure un lien vers la licence

        ## üîÑ Historique des Versions

        - **v1.0.0** ({datetime.now().strftime('%Y-%m-%d')}) : Version initiale avec {analysis['total_images']:,} images
        - {len(analysis['waste_types'])} types de d√©chets √† travers {len(analysis['zones'])} zones
        - M√©tadonn√©es compl√®tes avec {len(analysis['colors'])} variantes de couleur
        - Focus sur le contexte urbain africain

        ---

        *G√©n√©r√© le {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | Taille du Dataset : {analysis['total_size_mb']:.1f} MB | Images : {analysis['total_images']:,}*
    """
        return card_content

    def _creer_tableau_distribution(self, counter: Counter, header1: str, header2: str) -> str:
        """Cr√©er un tableau markdown √† partir d'un objet Counter"""
        table = f"| {header1} | {header2} | Pourcentage |\n"
        table += "|" + "-" * (len(header1) + 2) + "|" + "-" * (len(header2) + 2) + "|" + "-" * 13 + "|\n"
        
        total = sum(counter.values())
        for item, count in counter.most_common():
            percentage = (count / total) * 100
            table += f"| {item} | {count:,} | {percentage:.1f}% |\n"
        
        return table
    
    def uploader_carte_dataset(self, private: bool = False):
        """G√©n√©rer et uploader une carte de dataset compl√®te"""
        logger.info("G√©n√©ration de la carte de dataset compl√®te...")
        
        # Analyser le dataset
        analysis = self.analyser_dataset()
        
        # Cr√©er la carte compl√®te
        dataset_card = self.creer_carte_complete(analysis)
        
        # Sauvegarder localement d'abord
        readme_path = "README_complet.md"
        with open(readme_path, 'w', encoding='utf-8') as f:
            f.write(dataset_card)
        
        logger.info(f"Carte du dataset sauvegard√©e localement : {readme_path}")
        
        # Uploader vers Hugging Face
        try:
            self.api.upload_file(
                path_or_fileobj=readme_path,
                path_in_repo="README.md",
                repo_id=self.repo_name,
                repo_type="dataset",
                commit_message="Ajouter une carte de dataset compl√®te avec analyse d√©taill√©e et documentation"
            )
            
            logger.info(f"Carte de dataset compl√®te upload√©e avec succ√®s !")
            logger.info(f"Voir √† : https://huggingface.co/datasets/{self.repo_name}")
            
        except Exception as e:
            logger.error(f"Erreur lors de l'upload de la carte du dataset : {e}")
            raise
        
        finally:
            # Nettoyer le fichier local
            if os.path.exists(readme_path):
                os.remove(readme_path)
        
        return analysis

# Exemple d'utilisation
if __name__ == "__main__":
    # Configuration
    DATASET_PATH = "waste_dataset"  # Chemin vers votre dataset local
    REPO_NAME = "Yoannoza/waste-dataset"  # Nom de votre d√©p√¥t HF
    HF_TOKEN = os.getenv("HF_TOKEN")  # Token Hugging Face
    
    try:
        # Cr√©er le g√©n√©rateur de carte
        generateur_carte = GenerateurCarteDatasetComplet(DATASET_PATH, REPO_NAME)
        
        # Se connecter √† Hugging Face
        generateur_carte.login_hf(HF_TOKEN)
        
        # G√©n√©rer et uploader la carte de dataset compl√®te
        analysis = generateur_carte.uploader_carte_dataset(private=False)
        
        print(f"\n‚úÖ Carte du dataset upload√©e avec succ√®s !")
        print(f"üìä Statistiques du Dataset :")
        print(f"   ‚Ä¢ Total Images : {analysis['total_images']:,}")
        print(f"   ‚Ä¢ Types de D√©chets : {len(analysis['waste_types'])}")
        print(f"   ‚Ä¢ Zones : {len(analysis['zones'])}")
        print(f"   ‚Ä¢ Taille Totale : {analysis['total_size_mb']:.1f} MB")
        print(f"üîó Voir √† : https://huggingface.co/datasets/{REPO_NAME}")
        
    except Exception as e:
        print(f"‚ùå Erreur : {e}")
        logging.error(f"√âchec de la g√©n√©ration de la carte du dataset : {e}")